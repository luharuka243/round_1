{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Set, Tuple\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def remove_exact_duplicates(df,column_name):\n",
    "    df=df.drop_duplicates(subset=[column_name])\n",
    "    return df\n",
    "\n",
    "class MinHashLSH:\n",
    "    def __init__(self, num_perm: int = 100, num_bands: int = 20):\n",
    "        \"\"\"\n",
    "        Initialize LSH with MinHash for text similarity detection\n",
    "        \n",
    "        Args:\n",
    "            num_perm: Number of permutations for MinHash\n",
    "            num_bands: Number of bands for LSH (affects performance/accuracy tradeoff)\n",
    "        \"\"\"\n",
    "        self.num_perm = num_perm\n",
    "        self.num_bands = num_bands\n",
    "        self.rows_per_band = self.num_perm // self.num_bands\n",
    "        self.hash_tables = [defaultdict(list) for _ in range(self.num_bands)]\n",
    "        self.documents = {}\n",
    "        \n",
    "    def _preprocess_text(self, text: str) -> str:\n",
    "        \"\"\"Clean and normalize text.\"\"\"\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)\n",
    "        return text\n",
    "    \n",
    "    def _get_shingles(self, text: str, k: int = 3) -> Set[str]:\n",
    "        \"\"\"Convert text to k-shingles.\"\"\"\n",
    "        text = self._preprocess_text(text)\n",
    "        return set(text[i:i+k] for i in range(len(text)-k+1))\n",
    "    \n",
    "    def _minhash_signature(self, shingles: Set[str]) -> np.ndarray:\n",
    "        \"\"\"Generate MinHash signature for a set of shingles.\"\"\"\n",
    "        signature = np.full(self.num_perm, np.inf)\n",
    "        \n",
    "        for shingle in shingles:\n",
    "            for i in range(self.num_perm):\n",
    "                hash_val = hash(f\"{i}_{shingle}\")\n",
    "                signature[i] = min(signature[i], hash_val)\n",
    "        \n",
    "        return signature\n",
    "    \n",
    "    def _get_bands(self, signature: np.ndarray) -> List[Tuple]:\n",
    "        \"\"\"Split signature into bands.\"\"\"\n",
    "        return [tuple(signature[i:i + self.rows_per_band]) \n",
    "                for i in range(0, len(signature), self.rows_per_band)]\n",
    "    \n",
    "    def _jaccard_similarity(self, sig1: np.ndarray, sig2: np.ndarray) -> float:\n",
    "        \"\"\"Calculate Jaccard similarity between two MinHash signatures.\"\"\"\n",
    "        return np.mean(sig1 == sig2)\n",
    "    \n",
    "    def add_document(self, doc_id: str, text: str):\n",
    "        \"\"\"Add a document to the LSH index.\"\"\"\n",
    "        shingles = self._get_shingles(text)\n",
    "        signature = self._minhash_signature(shingles)\n",
    "        self.documents[doc_id] = signature\n",
    "        \n",
    "        for band_idx, band in enumerate(self._get_bands(signature)):\n",
    "            self.hash_tables[band_idx][band].append(doc_id)\n",
    "    \n",
    "    def find_duplicates(self, threshold: float) -> List[Tuple[str, str, float]]:\n",
    "        \"\"\"Find all pairs of documents with similarity above threshold.\"\"\"\n",
    "        candidate_pairs = set()\n",
    "        \n",
    "        for hash_table in self.hash_tables:\n",
    "            for bucket in hash_table.values():\n",
    "                if len(bucket) > 1:\n",
    "                    for i in range(len(bucket)):\n",
    "                        for j in range(i + 1, len(bucket)):\n",
    "                            candidate_pairs.add(tuple(sorted([bucket[i], bucket[j]])))\n",
    "        \n",
    "        duplicates = []\n",
    "        for doc1_id, doc2_id in candidate_pairs:\n",
    "            similarity = self._jaccard_similarity(\n",
    "                self.documents[doc1_id],\n",
    "                self.documents[doc2_id]\n",
    "            )\n",
    "            if similarity >= threshold:\n",
    "                duplicates.append((doc1_id, doc2_id, similarity))\n",
    "                \n",
    "        return duplicates\n",
    "    \n",
    "    def deduplicate(self, texts: List[str], threshold: float) -> List[str]:\n",
    "        \"\"\"Remove similar texts based on a given similarity threshold.\"\"\"\n",
    "        self.hash_tables = [defaultdict(list) for _ in range(self.num_bands)]\n",
    "        self.documents = {}\n",
    "        \n",
    "        for i, text in enumerate(texts):\n",
    "            self.add_document(str(i), text)\n",
    "            \n",
    "        duplicates = self.find_duplicates(threshold)\n",
    "        \n",
    "        to_remove = set()\n",
    "        for doc1_id, doc2_id, _ in duplicates:\n",
    "            to_remove.add(int(doc2_id))\n",
    "        \n",
    "        return [text for i, text in enumerate(texts) if i not in to_remove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH=\"../data.csv\"\n",
    "COMPLAIN_COLUMN=\"crimeaditionalinfo\"\n",
    "df=pd.read_csv(FILE_PATH)[[COMPLAIN_COLUMN]]\n",
    "\n",
    "# Remove exact duplicates\n",
    "print(\"Length of df before removing exact duplicates: \",len(df))\n",
    "df = remove_exact_duplicates(df,COMPLAIN_COLUMN)\n",
    "print(\"Length of df after removing exact duplicates: \",len(df))\n",
    "\n",
    "# Remove similar texts using MinHashLSH\n",
    "minhash_lsh = MinHashLSH(num_perm=100, num_bands=20)\n",
    "threshold = 0.9\n",
    "unique_texts = minhash_lsh.deduplicate(df[COMPLAIN_COLUMN].tolist(), threshold)\n",
    "df=pd.DataFrame(unique_texts,columns=[COMPLAIN_COLUMN])\n",
    "print(\"Length of df after removing similar texts: \",len(df))\n",
    "df.to_csv(FILE_PATH,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
