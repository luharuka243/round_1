{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlpaug.util.file.download import DownloadUtil\n",
    "\n",
    "# Note all the below are not finetuned model, they are embeddings for contexutal information\n",
    "DownloadUtil.download_word2vec(dest_dir='.') # Download word2vec\n",
    "DownloadUtil.download_glove(model_name='glove.6B', dest_dir='.') # Download GloVe\n",
    "DownloadUtil.download_fasttext(model_name='wiki-news-300d-1M', dest_dir='.') # Download fasttext\n",
    "\n",
    "\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug.augmenter.sentence as nas\n",
    "import nlpaug.augmenter.char as nac\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"]=\"true\"\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list(mixed_list):\n",
    "    \"\"\"\n",
    "    Flattens a list containing strings or lists of strings.\n",
    "    \n",
    "    Args:\n",
    "        mixed_list (list): A list containing strings and lists of strings.\n",
    "\n",
    "    Returns:\n",
    "        list: A flattened list of strings.\n",
    "    \"\"\"\n",
    "    flattened = []\n",
    "    for item in mixed_list:\n",
    "        if isinstance(item, list):  # Check if the item is a list\n",
    "            flattened.extend(item)  # Extend the flattened list with the inner list\n",
    "        elif isinstance(item, str):  # Check if the item is a string\n",
    "            flattened.append(item)  # Add the string to the flattened list\n",
    "    return flattened\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedTextAugmenter:\n",
    "    def __init__(self, languages=None):\n",
    "        \"\"\"\n",
    "        Initialize augmenters with optional language support\n",
    "        \n",
    "        Args:\n",
    "            languages (list): List of language codes for translation augmentation\n",
    "        \"\"\"\n",
    "        self.languages = languages or ['fr', 'de', 'es']\n",
    "        \n",
    "        # Word-level augmenters\n",
    "        self.synonym_aug = naw.SynonymAug(aug_src='wordnet')\n",
    "        self.word_embedding_aug = naw.WordEmbsAug(\n",
    "            model_type='word2vec', \n",
    "            model_path='GoogleNews-vectors-negative300.bin'  # Optional: specify a pre-trained model\n",
    "        )\n",
    "        \n",
    "        \n",
    "        # Back-translation augmenters\n",
    "        self.back_translation_augs = [\n",
    "            naw.BackTranslationAug(\n",
    "                from_model_name=f'Helsinki-NLP/opus-mt-en-{lang}',\n",
    "                to_model_name=f'Helsinki-NLP/opus-mt-{lang}-en',device=\"cuda\"\n",
    "            ) for lang in self.languages\n",
    "        ]\n",
    "        \n",
    "        # Sentence-level augmenter\n",
    "        self.sentence_aug = nas.RandomSentAug()\n",
    "\n",
    "    def augment_text(self, text, num_augmentations=5, augmentation_techniques=None, categories=None):\n",
    "        \"\"\"\n",
    "        Apply multiple augmentation techniques to the input text\n",
    "        \n",
    "        Args:\n",
    "            text (str): Input text to augment\n",
    "            num_augmentations (int): Number of augmentations to generate\n",
    "            augmentation_techniques (list): Specific techniques to use\n",
    "        \n",
    "        Returns:\n",
    "            list: Augmented text variations\n",
    "        \"\"\"\n",
    "        # Default augmentation techniques if not specified\n",
    "        if augmentation_techniques is None:\n",
    "            augmentation_techniques = [\n",
    "                'synonym',\n",
    "                'word_embedding',\n",
    "                'back_translation',\n",
    "                'sentence_swap'\n",
    "            ]\n",
    "        augmented_texts = []\n",
    "        \n",
    "        # Synonym Replacement\n",
    "        print(f\"Generating the data for categories {categories} using synonym\")\n",
    "        if 'synonym' in augmentation_techniques:\n",
    "            augmented_texts.extend(\n",
    "                [self.synonym_aug.augment(text) for _ in range(num_augmentations//2)]\n",
    "            )\n",
    "        \n",
    "        # Word Embedding Augmentation\n",
    "        print(f\"Generating the data for categories {categories} using word_embedding\")\n",
    "        if 'word_embedding' in augmentation_techniques:\n",
    "            try:\n",
    "                augmented_texts.extend(\n",
    "                    [self.word_embedding_aug.augment(text) for _ in range(num_augmentations//2)]\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Word embedding augmentation failed: {e}\")\n",
    "        \n",
    "        # Back Translation\n",
    "        print(f\"Generating the data for categories {categories} using back_translation\")\n",
    "        if 'back_translation' in augmentation_techniques:\n",
    "            for translator in self.back_translation_augs:\n",
    "                try:\n",
    "                    augmented_texts.append(translator.augment(text)[0])\n",
    "                except Exception as e:\n",
    "                    print(f\"Back translation augmentation failed: {e}\")\n",
    "        \n",
    "        # Sentence-level Augmentation\n",
    "        print(f\"Generating the data for categories {categories} using sentence_swapping\")\n",
    "        if 'sentence_swap' in augmentation_techniques:\n",
    "            augmented_texts.append(self.sentence_aug.augment(text)[0])\n",
    "            \n",
    "            \n",
    "        augmented_texts=flatten_list(augmented_texts)\n",
    "        # Remove duplicates and limit to unique augmentations\n",
    "        unique_augmented_texts = list(set(augmented_texts))\n",
    "        \n",
    "        print(f\"Total unique generated data text for {categories} is {len(unique_augmented_texts)}\")\n",
    "        return unique_augmented_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_augmenter = AdvancedTextAugmenter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_original_mapped_sub_category(df, per_sample_target_count=1000, text_columns=None,category=None,category_column=None):\n",
    "    \"\"\"\n",
    "    Augment rows for original_mapped_sub_category with fewer than target_count instances\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame\n",
    "        target_count (int): Target number of instances per category\n",
    "        text_columns (list): Columns to apply text augmentation\n",
    "        output_file (str): Path to save augmented data CSV\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Augmented DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    # Augmented samples storage    \n",
    "    # Augmentation for each low-count category\n",
    "    print(\"*\"*75)\n",
    "    print(f\"Generation starts for category: {category}\")\n",
    "    \n",
    "    # Get subset of current category\n",
    "    category_subset = df[df[category_column] == category]\n",
    "    current_count = len(category_subset)\n",
    "    needed_count = per_sample_target_count - current_count\n",
    "    base_sample_text = category_subset.sample(n=1).crimeaditionalinfo.to_list()\n",
    "    augmented_variations = text_augmenter.augment_text(\n",
    "                base_sample_text,\n",
    "                num_augmentations=needed_count,\n",
    "                categories=category\n",
    "            )\n",
    "    augmented_variations_df=pd.DataFrame({\n",
    "        \"content\":augmented_variations,\n",
    "        category_column:[category for _ in range(len(augmented_variations))]\n",
    "    })\n",
    "    return augmented_variations_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>category</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>crimeaditionalinfo</th>\n",
       "      <th>final_category</th>\n",
       "      <th>final_subcategory</th>\n",
       "      <th>category_justification</th>\n",
       "      <th>subcategory_justification</th>\n",
       "      <th>confidence_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Online Cyber Trafficking</td>\n",
       "      <td>Online Trafficking</td>\n",
       "      <td>SIR I HAVE GET SMS WITH PRE APPORVED LOAN  IJU...</td>\n",
       "      <td>online_financial_fraud</td>\n",
       "      <td>fraud_callvishing</td>\n",
       "      <td>The content describes a fraudulent loan scheme...</td>\n",
       "      <td>The user was contacted via WhatsApp and pressu...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Online Cyber Trafficking</td>\n",
       "      <td>Online Trafficking</td>\n",
       "      <td>this number frauder call me I had ordered on a...</td>\n",
       "      <td>online_financial_fraud</td>\n",
       "      <td>debitcredit_card_fraudsim_swap_fraud</td>\n",
       "      <td>The content describes a situation where the us...</td>\n",
       "      <td>The user describes a debit card being used fra...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Online Cyber Trafficking</td>\n",
       "      <td>Online Trafficking</td>\n",
       "      <td>I have received a notification by chrome he sa...</td>\n",
       "      <td>online_financial_fraud</td>\n",
       "      <td>debitcredit_card_fraudsim_swap_fraud</td>\n",
       "      <td>The content describes a user losing money afte...</td>\n",
       "      <td>The user's account balance being deducted afte...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>Online Cyber Trafficking</td>\n",
       "      <td>Online Trafficking</td>\n",
       "      <td>The app is in playstore with name of the five ...</td>\n",
       "      <td>online_financial_fraud</td>\n",
       "      <td>attacks_or_incidents_affecting_digital_payment...</td>\n",
       "      <td>The content describes a scenario where the use...</td>\n",
       "      <td>The mention of investing money through an app ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.0</td>\n",
       "      <td>Online Cyber Trafficking</td>\n",
       "      <td>Online Trafficking</td>\n",
       "      <td>MY TR ID SBIUPI ID mpMTiRBaQPTVUZXBAwlwhDqcsUu...</td>\n",
       "      <td>online_financial_fraud</td>\n",
       "      <td>upi_related_frauds</td>\n",
       "      <td>The content mentions SBIUPI ID and OTP, indica...</td>\n",
       "      <td>The mention of UPI ID suggests the fraud is re...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                  category        sub_category  \\\n",
       "0         0.0  Online Cyber Trafficking  Online Trafficking   \n",
       "1         1.0  Online Cyber Trafficking  Online Trafficking   \n",
       "2         3.0  Online Cyber Trafficking  Online Trafficking   \n",
       "3         6.0  Online Cyber Trafficking  Online Trafficking   \n",
       "4        14.0  Online Cyber Trafficking  Online Trafficking   \n",
       "\n",
       "                                  crimeaditionalinfo          final_category  \\\n",
       "0  SIR I HAVE GET SMS WITH PRE APPORVED LOAN  IJU...  online_financial_fraud   \n",
       "1  this number frauder call me I had ordered on a...  online_financial_fraud   \n",
       "2  I have received a notification by chrome he sa...  online_financial_fraud   \n",
       "3  The app is in playstore with name of the five ...  online_financial_fraud   \n",
       "4  MY TR ID SBIUPI ID mpMTiRBaQPTVUZXBAwlwhDqcsUu...  online_financial_fraud   \n",
       "\n",
       "                                   final_subcategory  \\\n",
       "0                                  fraud_callvishing   \n",
       "1               debitcredit_card_fraudsim_swap_fraud   \n",
       "2               debitcredit_card_fraudsim_swap_fraud   \n",
       "3  attacks_or_incidents_affecting_digital_payment...   \n",
       "4                                 upi_related_frauds   \n",
       "\n",
       "                              category_justification  \\\n",
       "0  The content describes a fraudulent loan scheme...   \n",
       "1  The content describes a situation where the us...   \n",
       "2  The content describes a user losing money afte...   \n",
       "3  The content describes a scenario where the use...   \n",
       "4  The content mentions SBIUPI ID and OTP, indica...   \n",
       "\n",
       "                           subcategory_justification  confidence_score  \n",
       "0  The user was contacted via WhatsApp and pressu...               NaN  \n",
       "1  The user describes a debit card being used fra...               NaN  \n",
       "2  The user's account balance being deducted afte...               NaN  \n",
       "3  The mention of investing money through an app ...               NaN  \n",
       "4  The mention of UPI ID suggests the fraud is re...               NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"../data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agumented_data=augment_original_mapped_sub_category(df,text_columns=\"crimeadditionalinfo\",category_column=\"sub_category\",category=\"online_financial_fraud\")\n",
    "agumented_data.to_csv(\"Augumented_data_for_online_financial_fraud.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
