{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "\n",
    "from GdriveModels import download_google_drive_folder\n",
    "if not os.path.exists('models_gdrive'):\n",
    "    download_google_drive_folder()\n",
    "\n",
    "class CyberCrimeDataset(Dataset):\n",
    "    \"\"\"Dataset class for cyber crime text classification\"\"\"\n",
    "    def __init__(self, texts: List[str], main_categories: List[str], \n",
    "                 categories: List[str], sub_categories: List[str],\n",
    "                 sub_category_names: List[str]):\n",
    "        self.texts = texts\n",
    "        self.main_categories = main_categories\n",
    "        self.categories = categories\n",
    "        self.sub_categories = sub_categories\n",
    "        self.sub_category_names = sub_category_names\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'text': self.texts[idx],\n",
    "            'category_names': self.main_categories[idx],\n",
    "            'retagged_category': self.categories[idx],\n",
    "            'retagged_sub_category': self.sub_categories[idx],\n",
    "            'sub_category_names': self.sub_category_names[idx]\n",
    "        }\n",
    "\n",
    "def custom_collate(batch):\n",
    "    \"\"\"Custom collate function to handle batch processing\"\"\"\n",
    "    return {\n",
    "        'text': [item['text'] for item in batch],\n",
    "        'category_names': [item['category_names'] for item in batch],\n",
    "        'retagged_category': [item['retagged_category'] for item in batch],\n",
    "        'retagged_sub_category': [item['retagged_sub_category'] for item in batch],\n",
    "        'sub_category_names': [item['sub_category_names'] for item in batch]\n",
    "    }\n",
    "\n",
    "def evaluate_predictions(y_true: List[str], y_pred: List[str], level_name: str):\n",
    "    \"\"\"\n",
    "    Evaluate predictions for a given hierarchy level\n",
    "    \n",
    "    Args:\n",
    "        y_true: List of true labels\n",
    "        y_pred: List of predicted labels\n",
    "        level_name: Name of the hierarchy level being evaluated\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== {level_name} Metrics ===\")\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Generate and print classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    \n",
    "    # Generate confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "def process_batch(batch: Dict, encoder, models: Dict, selectors: Dict, \n",
    "                 label_encoders: Dict, category_to_sub_category: Dict,\n",
    "                 master_mapper: Dict) -> Dict[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Process a batch of texts through the model hierarchy\n",
    "    \n",
    "    Args:\n",
    "        batch: Dictionary containing batch data\n",
    "        encoder: Sentence transformer encoder\n",
    "        models: Dictionary of trained models\n",
    "        selectors: Dictionary of feature selectors\n",
    "        label_encoders: Dictionary of label encoders\n",
    "        category_to_sub_category: Mapping of categories to subcategories\n",
    "        master_mapper: Master mapping dictionary\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing predictions for all hierarchy levels\n",
    "    \"\"\"\n",
    "    texts = [str(text).lower() for text in batch['text']]\n",
    "    \n",
    "    batch_results = {\n",
    "        'pred_category_names': [],\n",
    "        'pred_retagged_category': [],\n",
    "        'pred_retagged_sub_category': [],\n",
    "        'pred_sub_category_names': []\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Encode all texts in batch\n",
    "        text_embeddings = encoder.encode(texts, show_progress_bar=False)\n",
    "        text_embeddings = text_embeddings.reshape(len(texts), -1)\n",
    "        \n",
    "        # Predict main categories\n",
    "        main_features = selectors['category_names'].transform(text_embeddings)\n",
    "        main_cat_pred = models['category_names'].predict(main_features)\n",
    "        main_categories = label_encoders['category_names'].inverse_transform(main_cat_pred)\n",
    "        \n",
    "        # Process each text in batch\n",
    "        for idx, category_names in enumerate(main_categories):\n",
    "            batch_results['pred_category_names'].append(category_names)\n",
    "            \n",
    "            try:\n",
    "                # Predict category\n",
    "                category_model_key = f'category_{category_names.replace(\" \", \"_\").replace(\"/\", \"_\").replace(\"&\", \"and\")}'\n",
    "                single_embedding = text_embeddings[idx:idx+1]\n",
    "                \n",
    "                category_features = selectors[category_model_key].transform(single_embedding)\n",
    "                cat_pred = models[category_model_key].predict(category_features)\n",
    "                category = label_encoders[category_model_key].inverse_transform(cat_pred)[0]\n",
    "                \n",
    "                # Predict subcategory\n",
    "                if category in category_to_sub_category and len(category_to_sub_category[category]) > 1:\n",
    "                    sub_category_names_model_key = f'sub_category_names_{category.replace(\" \", \"_\").replace(\"/\", \"_\").replace(\"&\", \"and\")}'\n",
    "                    sub_features = selectors[sub_category_names_model_key].transform(single_embedding)\n",
    "                    mapped_sub_cat_pred = models[sub_category_names_model_key].predict(sub_features)\n",
    "                    sub_category_names = label_encoders[sub_category_names_model_key].inverse_transform(mapped_sub_cat_pred)[0]\n",
    "                    sub_category = find_immediate_key(master_mapper, sub_category_names)\n",
    "                else:\n",
    "                    sub_category_names = category_to_sub_category[category][0]\n",
    "                    sub_category = find_immediate_key(master_mapper, sub_category_names)\n",
    "                \n",
    "            except KeyError as e:\n",
    "                print(f\"Warning: Model not found for prediction chain: {e}\")\n",
    "                category = \"unknown\"\n",
    "                sub_category_names = \"unknown\"\n",
    "                sub_category = \"unknown\"\n",
    "            \n",
    "            batch_results['pred_retagged_category'].append(category)\n",
    "            batch_results['pred_retagged_sub_category'].append(sub_category)\n",
    "            batch_results['pred_sub_category_names'].append(sub_category_names)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in processing batch: {str(e)}\")\n",
    "        # Fill with unknowns for this batch\n",
    "        batch_size = len(texts)\n",
    "        for key in batch_results:\n",
    "            batch_results[key].extend(['unknown'] * batch_size)\n",
    "    \n",
    "    return batch_results\n",
    "\n",
    "def run_inference_pipeline(test_df: pd.DataFrame, \n",
    "                         encoder, models: Dict, \n",
    "                         selectors: Dict, \n",
    "                         label_encoders: Dict,\n",
    "                         category_to_sub_category: Dict,\n",
    "                         master_mapper: Dict,\n",
    "                         batch_size: int = 64) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Run the complete inference pipeline\n",
    "    \n",
    "    Args:\n",
    "        test_df: DataFrame containing test data\n",
    "        encoder: Sentence transformer encoder\n",
    "        models: Dictionary of trained models\n",
    "        selectors: Dictionary of feature selectors\n",
    "        label_encoders: Dictionary of label encoders\n",
    "        category_to_sub_category: Mapping of categories to subcategories\n",
    "        master_mapper: Master mapping dictionary\n",
    "        batch_size: Batch size for processing\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame containing all predictions and metrics\n",
    "    \"\"\"\n",
    "    # Create dataset and dataloader\n",
    "    dataset = CyberCrimeDataset(\n",
    "        texts=test_df['content_processed'].apply(lambda x: str(x).lower()).tolist(),\n",
    "        main_categories=test_df.get('category_names', ['unknown'] * len(test_df)),\n",
    "        categories=test_df['retagged_category'].tolist(),\n",
    "        sub_categories=test_df['retagged_sub_category'].tolist(),\n",
    "        sub_category_names=test_df[\"sub_category_names\"].tolist(),\n",
    "    )\n",
    "\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=custom_collate,\n",
    "        num_workers=0\n",
    "    )\n",
    "\n",
    "    # Initialize results dictionary\n",
    "    results = {\n",
    "        'true_category_names': [],\n",
    "        'pred_category_names': [],\n",
    "        'true_retagged_category': [],\n",
    "        'pred_retagged_category': [],\n",
    "        'true_retagged_sub_category': [],\n",
    "        'pred_retagged_sub_category': [],\n",
    "        'true_sub_category_names': [],\n",
    "        'pred_sub_category_names': []\n",
    "    }\n",
    "\n",
    "    # Process batches\n",
    "    print(\"\\nProcessing batches...\")\n",
    "    total_batches = len(dataloader)\n",
    "\n",
    "    with tqdm(total=total_batches, desc=\"Processing\") as pbar:\n",
    "        for batch_idx, batch in enumerate(dataloader):\n",
    "            # Get predictions for batch\n",
    "            batch_predictions = process_batch(\n",
    "                batch, encoder, models, selectors, \n",
    "                label_encoders, category_to_sub_category, \n",
    "                master_mapper\n",
    "            )\n",
    "            \n",
    "            # Store results\n",
    "            if 'category_names' in batch:\n",
    "                results['true_category_names'].extend(batch['category_names'])\n",
    "            results['pred_category_names'].extend(batch_predictions['pred_category_names'])\n",
    "            results['true_retagged_category'].extend(batch['retagged_category'])\n",
    "            results['pred_retagged_category'].extend(batch_predictions['pred_retagged_category'])\n",
    "            results['true_sub_category_names'].extend(batch['sub_category_names'])\n",
    "            results['pred_sub_category_names'].extend(batch_predictions['pred_sub_category_names'])\n",
    "            results['true_retagged_sub_category'].extend(batch['retagged_sub_category'])\n",
    "            results['pred_retagged_sub_category'].extend(batch_predictions['pred_retagged_sub_category'])\n",
    "            \n",
    "            # Update progress and show intermediate metrics\n",
    "            pbar.update(1)\n",
    "            if (batch_idx + 1) % max(1, total_batches // 10) == 0:\n",
    "                show_intermediate_metrics(results, batch_idx, total_batches, pbar)\n",
    "\n",
    "    # Convert results to DataFrame and calculate final metrics\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv('prediction_results.csv', index=False)\n",
    "    \n",
    "    print(\"\\nCalculating final metrics...\")\n",
    "    calculate_final_metrics(results_df)\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "def show_intermediate_metrics(results: Dict, batch_idx: int, \n",
    "                            total_batches: int, pbar: tqdm):\n",
    "    \"\"\"Show intermediate metrics during batch processing\"\"\"\n",
    "    pbar.write(f\"\\nBatch {batch_idx + 1}/{total_batches}\")\n",
    "    \n",
    "    for level in ['retagged_category', 'category_names', 'sub_category_names', 'retagged_sub_category']:\n",
    "        true_key = f'true_{level}'\n",
    "        pred_key = f'pred_{level}'\n",
    "        if true_key in results and len(results[true_key]) > 0:\n",
    "            current_accuracy = accuracy_score(\n",
    "                results[true_key][:len(results[pred_key])],\n",
    "                results[pred_key]\n",
    "            )\n",
    "            pbar.write(f\"Current {level} Accuracy: {current_accuracy:.4f}\")\n",
    "\n",
    "def clean_json_mapping(json_mapping):\n",
    "    \"\"\"\n",
    "    Cleans a JSON mapping by replacing special characters and spaces with * or _,\n",
    "    and removing consecutive special characters.\n",
    "    \n",
    "    Args:\n",
    "        json_mapping (dict): Input JSON mapping to clean\n",
    "        \n",
    "    Returns:\n",
    "        dict: Cleaned JSON mapping\n",
    "    \"\"\"\n",
    "    def clean_string(s):\n",
    "        if not isinstance(s, str):\n",
    "            return s\n",
    "        \n",
    "        # Replace spaces with underscore\n",
    "        s = s.replace(' ', '_')\n",
    "        \n",
    "        # Replace special characters with asterisk\n",
    "        s = re.sub(r'[^a-zA-Z0-9_.]', '*', s)\n",
    "        s = s.replace(\".\",\"\")\n",
    "        \n",
    "        # Remove consecutive special characters\n",
    "        s = re.sub(r'[*_]+', lambda m: '_' if '_' in m.group() else '_', s)\n",
    "        \n",
    "        return s\n",
    "    \n",
    "    def process_value(value):\n",
    "        if isinstance(value, dict):\n",
    "            return {clean_string(k): process_value(v) for k, v in value.items()}\n",
    "        elif isinstance(value, list):\n",
    "            return [clean_string(item) for item in value]\n",
    "        else:\n",
    "            return clean_string(value)\n",
    "    \n",
    "    return process_value(json_mapping)\n",
    "\n",
    "def calculate_final_metrics(results_df: pd.DataFrame):\n",
    "    \"\"\"Calculate and display final metrics for all hierarchy levels\"\"\"\n",
    "    if 'true_category_names' in results_df.columns and results_df['true_category_names'].iloc[0] != 'unknown':\n",
    "        evaluate_predictions(\n",
    "            results_df['true_category_names'],\n",
    "            results_df['pred_category_names'],\n",
    "            'Main Category'\n",
    "        )\n",
    "\n",
    "    evaluate_predictions(\n",
    "        results_df['true_retagged_category'],\n",
    "        results_df['pred_retagged_category'],\n",
    "        'retagged_category'\n",
    "    )\n",
    "\n",
    "    evaluate_predictions(\n",
    "        results_df['true_sub_category_names'],\n",
    "        results_df['pred_sub_category_names'],\n",
    "        'Mapped Sub-Category'\n",
    "    )\n",
    "\n",
    "    evaluate_predictions(\n",
    "        results_df['true_retagged_sub_category'],\n",
    "        results_df['pred_retagged_sub_category'],\n",
    "        'Sub-Category'\n",
    "    )\n",
    "\n",
    "    # Calculate overall accuracy across all levels\n",
    "    overall_accuracy = (\n",
    "        (results_df['true_category_names'] == results_df['pred_category_names']) &\n",
    "        (results_df['true_retagged_category'] == results_df['pred_retagged_category']) &\n",
    "        (results_df['true_sub_category_names'] == results_df['pred_sub_category_names'])\n",
    "    ).mean()\n",
    "\n",
    "    print(\"\\n=== Overall Results ===\")\n",
    "    print(f\"Complete Hierarchy Accuracy: {overall_accuracy:.4f}\")\n",
    "    \n",
    "# Mappings\n",
    "category_names_to_category = clean_json_mapping({\n",
    "            \"women/child related crime\": [\n",
    "                \"child pornography cpchild sexual abuse material csam\",\n",
    "                \"crime against women & children\",\n",
    "                \"online cyber trafficking\",\n",
    "                \"rapegang rape rgrsexually abusive content\",\n",
    "                \"sexually explicit act\",\n",
    "                \"sexually obscene material\"\n",
    "            ],\n",
    "            \"financial fraud crimes\": [\n",
    "                \"cryptocurrency crime\",\n",
    "                \"online financial fraud\",\n",
    "                \"online gambling  betting\"\n",
    "            ],\n",
    "            \"other cyber crime\": [\n",
    "                \"any other cyber crime\",\n",
    "                \"cyber attack/ dependent crimes\",\n",
    "                \"cyber terrorism\",\n",
    "                \"hacking  damage to computercomputer system etc\",\n",
    "                \"online and social media related crime\",\n",
    "                \"report unlawful content\"\n",
    "            ]\n",
    "        })\n",
    "\n",
    "category_to_sub_category = clean_json_mapping({\n",
    "            \"any other cyber crime\": [\n",
    "                \"other\",\n",
    "                \"supply chain attacks\"\n",
    "            ],\n",
    "            \"child pornography cpchild sexual abuse material csam\": [\n",
    "                \"child pornography cpchild sexual abuse material csam\"\n",
    "            ],\n",
    "            \"crime against women & children\": [\n",
    "                \"sexual harassment\",\n",
    "                \"computer generated csam/csem\"\n",
    "            ],\n",
    "            \"cryptocurrency crime\": [\n",
    "                \"cryptocurrency fraud\"\n",
    "            ],\n",
    "            \"cyber attack/ dependent crimes\": [\n",
    "                \"sql injection\",\n",
    "                \"ransomware attack\",\n",
    "                \"malware attack\",\n",
    "                \"malicious code attacks (specifically mentioning virus, worm, trojan, bots, spyware, cryptominers)\",\n",
    "                \"data breach/theft\",\n",
    "                \"data leaks\",\n",
    "                \"hacking/defacement\",\n",
    "                \"zero-day exploits\",\n",
    "                \"malicious mobile app attacks\",\n",
    "                \"denial of service (dos)/distributed denial of service (ddos) attacks\",\n",
    "                \"tampering with computer source documents\"\n",
    "            ],\n",
    "            \"cyber terrorism\": [\n",
    "                \"cyber terrorism\",\n",
    "                \"cyber espionage\"\n",
    "            ],\n",
    "            \"hacking  damage to computercomputer system etc\": [\n",
    "                \"email hacking\",\n",
    "                \"unauthorised accessdata breach\",\n",
    "                \"compromise of critical systems/information\",\n",
    "                \"targeted scanning/probing of critical networks/systems\",\n",
    "                \"attacks on servers (database mail dns) and network devices (routers)\",\n",
    "                \"attacks on critical infrastructure, scada, operational technology systems, and wireless networks\",\n",
    "                \"attacks or suspicious activities affecting cloud computing systems servers software and applications\",\n",
    "                \"attacks or malicious suspicious activities affecting systems related to big data blockchain virtual assets and robotics\",\n",
    "                \"attacks on internet of things (iot) devices and associated systems, networks, and servers\",\n",
    "                \"attacks on systems related to artificial intelligence (ai) and machine learning (ml)\",\n",
    "                \"damage to computer computer systems etc\",\n",
    "                \"web application vulnerabilities\",\n",
    "            ],\n",
    "            \"online cyber trafficking\": [\n",
    "                \"online trafficking\"\n",
    "            ],\n",
    "            \"online financial fraud\": [\n",
    "                \"upi related frauds\",\n",
    "                \"aadhar enabled payment system (aeps) fraud\",\n",
    "                \"business email compromiseemail takeover\",\n",
    "                \"debitcredit card fraudsim swap fraud\",\n",
    "                \"ewallet related fraud\",\n",
    "                \"fraud callvishing\",\n",
    "                \"internet banking related fraud\",\n",
    "                \"attacks or incidents affecting digital payment systems\"\n",
    "            ],\n",
    "            \"online gambling  betting\": [\n",
    "                \"online gambling  betting\"\n",
    "            ],\n",
    "            \"online and social media related crime\": [\n",
    "                \"intimidating email\",\n",
    "                \"provocative speech for unlawful acts\",\n",
    "                \"email phishing\",\n",
    "                \"online job fraud\",\n",
    "                \"profile hacking identity theft\",\n",
    "                \"identity theft, spoofing, and phishing attacks\",\n",
    "                \"unauthorized social media access\",\n",
    "                \"cheating by impersonation\",\n",
    "                \"fake mobile apps\",\n",
    "                \"online matrimonial fraud\",\n",
    "                \"cyber bullying  stalking  sexting\",\n",
    "                \"fakeimpersonating profile\"\n",
    "            ],\n",
    "            \"rapegang rape rgrsexually abusive content\": [\n",
    "                \"rapegang rape rgrsexually abusive content\"\n",
    "            ],\n",
    "            \"report unlawful content\": [\n",
    "                \"against interest of sovereignty or integrity of india\",\n",
    "                \"disinformation or misinformation campaigns\"\n",
    "            ],\n",
    "            \"sexually explicit act\": [\n",
    "                \"sexually explicit act\"\n",
    "            ],\n",
    "            \"sexually obscene material\": [\n",
    "                \"sale publishing and transmitting obscene material/sexually explicit material\"\n",
    "            ]\n",
    "        })\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "def load_models(models_path='models_gdrive/models/') -> Tuple[object, Dict, Dict, Dict]:\n",
    "    \"\"\"\n",
    "    Load all saved models, encoders, and selectors from the specified path\n",
    "    \n",
    "    Args:\n",
    "        models_path (str): Path to directory containing saved models\n",
    "        \n",
    "    Returns:\n",
    "        Tuple containing:\n",
    "        - sentence encoder\n",
    "        - dictionary of trained models\n",
    "        - dictionary of label encoders\n",
    "        - dictionary of feature selectors\n",
    "    \"\"\"\n",
    "    print(\"Loading models...\")\n",
    "    models = {}\n",
    "    label_encoders = {}\n",
    "    selectors = {}\n",
    "    \n",
    "    # Load the same sentence transformer used in training\n",
    "    encoder = SentenceTransformer('paraphrase-MiniLM-L3-v2')\n",
    "    \n",
    "    # Load main category model components\n",
    "    try:\n",
    "        models['category_names'] = joblib.load(os.path.join(models_path, 'category_names_model.joblib'))\n",
    "        label_encoders['category_names'] = joblib.load(os.path.join(models_path, 'category_names_encoder.joblib'))\n",
    "        selectors['category_names'] = joblib.load(os.path.join(models_path, 'category_names_selector.joblib'))\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to load main category model components: {str(e)}\")\n",
    "    \n",
    "    # Load all category and subcategory models\n",
    "    model_files = list(Path(models_path).glob('*_model.joblib'))\n",
    "    for file in tqdm(model_files, desc=\"Loading models\"):\n",
    "        if file.name != 'category_names_model.joblib':\n",
    "            key = file.name.replace('_model.joblib', '')\n",
    "            try:\n",
    "                models[key] = joblib.load(file)\n",
    "                label_encoders[key] = joblib.load(str(file).replace('_model.joblib', '_encoder.joblib'))\n",
    "                selectors[key] = joblib.load(str(file).replace('_model.joblib', '_selector.joblib'))\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Failed to load model components for {key}: {str(e)}\")\n",
    "    \n",
    "    return encoder, models, label_encoders, selectors\n",
    "\n",
    "def predict_single(text: str, encoder, models: Dict, selectors: Dict, \n",
    "                  label_encoders: Dict, category_to_sub_category: Dict,\n",
    "                  master_mapper: Dict) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Process a single text through the hierarchical model chain\n",
    "    \n",
    "    Args:\n",
    "        text (str): Input text to classify\n",
    "        encoder: Sentence transformer encoder\n",
    "        models (Dict): Dictionary of trained models\n",
    "        selectors (Dict): Dictionary of feature selectors\n",
    "        label_encoders (Dict): Dictionary of label encoders\n",
    "        category_to_sub_category (Dict): Mapping from categories to subcategories\n",
    "        master_mapper (Dict): Master mapping of categories\n",
    "        \n",
    "    Returns:\n",
    "        Dict containing predictions for category_names, category, sub_category, \n",
    "        and sub_category_names\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Preprocess and encode text\n",
    "        processed_text = preprocess_text(text)\n",
    "        text_embedding = encoder.encode([processed_text], show_progress_bar=False)\n",
    "        text_embedding = text_embedding.reshape(1, -1)\n",
    "        \n",
    "        # Predict main category\n",
    "        main_features = selectors['category_names'].transform(text_embedding)\n",
    "        main_cat_pred = models['category_names'].predict(main_features)\n",
    "        category_names = label_encoders['category_names'].inverse_transform(main_cat_pred)[0]\n",
    "        \n",
    "        # Predict category based on main category\n",
    "        category_model_key = f'category_{category_names.replace(\" \", \"_\").replace(\"/\", \"_\").replace(\"&\", \"and\")}'\n",
    "        try:\n",
    "            category_features = selectors[category_model_key].transform(text_embedding)\n",
    "            cat_pred = models[category_model_key].predict(category_features)\n",
    "            category = label_encoders[category_model_key].inverse_transform(cat_pred)[0]\n",
    "        except KeyError:\n",
    "            print(f\"Warning: No category model found for {category_names}\")\n",
    "            return {\n",
    "                'pred_category_names': category_names,\n",
    "                'pred_retagged_category': 'unknown',\n",
    "                'pred_retagged_sub_category': 'unknown',\n",
    "                'pred_sub_category_names': 'unknown'\n",
    "            }\n",
    "        \n",
    "        # Predict subcategory if multiple options exist\n",
    "        if category in category_to_sub_category and len(category_to_sub_category[category]) > 1:\n",
    "            sub_category_names_model_key = f'sub_category_names_{category.replace(\" \", \"_\").replace(\"/\", \"_\").replace(\"&\", \"and\")}'\n",
    "            try:\n",
    "                sub_features = selectors[sub_category_names_model_key].transform(text_embedding)\n",
    "                mapped_sub_cat_pred = models[sub_category_names_model_key].predict(sub_features)\n",
    "                sub_category_names = label_encoders[sub_category_names_model_key].inverse_transform(mapped_sub_cat_pred)[0]\n",
    "                sub_category = find_immediate_key(master_mapper, sub_category_names)\n",
    "            except KeyError:\n",
    "                print(f\"Warning: No subcategory model found for {category}\")\n",
    "                sub_category_names = category_to_sub_category[category][0]\n",
    "                sub_category = find_immediate_key(master_mapper, sub_category_names)\n",
    "        else:\n",
    "            sub_category_names = category_to_sub_category[category][0]\n",
    "            sub_category = find_immediate_key(master_mapper, sub_category_names)\n",
    "        \n",
    "        return {\n",
    "            'pred_category_names': category_names,\n",
    "            'pred_retagged_category': category,\n",
    "            'pred_retagged_sub_category': sub_category,\n",
    "            'pred_sub_category_names': sub_category_names\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in prediction: {str(e)}\")\n",
    "        return {\n",
    "            'pred_category_names': 'unknown',\n",
    "            'pred_retagged_category': 'unknown',\n",
    "            'pred_retagged_sub_category': 'unknown',\n",
    "            'pred_sub_category_names': 'unknown'\n",
    "        }\n",
    "\n",
    "def find_immediate_key(dictionary, search_value):\n",
    "    \"\"\"\n",
    "    Find the immediate key for a given value in a nested dictionary.\n",
    "    \n",
    "    Args:\n",
    "    dictionary (dict): The nested dictionary to search\n",
    "    search_value (str): The value to find\n",
    "    \n",
    "    Returns:\n",
    "    str or None: The immediate key if found, None otherwise\n",
    "    \"\"\"\n",
    "    for outer_key, inner_dict in dictionary.items():\n",
    "        for inner_key, values in inner_dict.items():\n",
    "            if search_value in values:\n",
    "                return inner_key\n",
    "    return None\n",
    "\n",
    "def save_detailed_results(results_df: pd.DataFrame, test_df: pd.DataFrame):\n",
    "    \"\"\"Save detailed analysis of the results\"\"\"\n",
    "    # Combine original text with predictions\n",
    "    detailed_results = pd.concat([\n",
    "        test_df['content_processed'],\n",
    "        results_df\n",
    "    ], axis=1)\n",
    "    \n",
    "    # Add correctness columns\n",
    "    detailed_results['category_names_correct'] = (\n",
    "        detailed_results['true_category_names'] == \n",
    "        detailed_results['pred_category_names']\n",
    "    )\n",
    "    detailed_results['category_correct'] = (\n",
    "        detailed_results['true_retagged_category'] == \n",
    "        detailed_results['pred_retagged_category']\n",
    "    )\n",
    "    detailed_results['sub_category_correct'] = (\n",
    "        detailed_results['true_retagged_sub_category'] == \n",
    "        detailed_results['pred_retagged_sub_category']\n",
    "    )\n",
    "    \n",
    "    # Save to CSV\n",
    "    detailed_results.to_csv('detailed_prediction_results.csv', index=False)\n",
    "    \n",
    "    # Save error analysis\n",
    "    error_cases = detailed_results[\n",
    "        ~(detailed_results['category_names_correct'] & \n",
    "          detailed_results['category_correct'] & \n",
    "          detailed_results['sub_category_correct'])\n",
    "    ]\n",
    "    error_cases.to_csv('prediction_errors.csv', index=False)\n",
    "\n",
    "def analyze_examples(results_df: pd.DataFrame, test_df: pd.DataFrame, n_examples: int = 5):\n",
    "    \"\"\"Analyze specific examples from the results\"\"\"\n",
    "    print(\"\\n=== Example Predictions ===\")\n",
    "    \n",
    "    # Sample some random examples\n",
    "    indices = np.random.choice(len(results_df), min(n_examples, len(results_df)), replace=False)\n",
    "    \n",
    "    for idx in indices:\n",
    "        print(\"\\nText:\")\n",
    "        print(test_df['content_processed'].iloc[idx][:200] + \"...\")  # Show first 200 chars\n",
    "        \n",
    "        print(\"\\nPredictions:\")\n",
    "        print(f\"Main Category: {results_df['pred_category_names'].iloc[idx]} \"\n",
    "              f\"(True: {results_df['true_category_names'].iloc[idx]})\")\n",
    "        print(f\"Category: {results_df['pred_retagged_category'].iloc[idx]} \"\n",
    "              f\"(True: {results_df['true_retagged_category'].iloc[idx]})\")\n",
    "        print(f\"Sub-Category: {results_df['pred_retagged_sub_category'].iloc[idx]} \"\n",
    "              f\"(True: {results_df['true_retagged_sub_category'].iloc[idx]})\")\n",
    "        print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_mapper = {\n",
    "    \"any other cyber crime\": {\n",
    "        \"other\": [\n",
    "            \"other\",\n",
    "            \"supply chain attacks\"\n",
    "        ]\n",
    "    },\n",
    "    \"child pornography cpchild sexual abuse material csam\": {\n",
    "        \"child pornography cpchild sexual abuse material csam\": [\n",
    "            \"child pornography cpchild sexual abuse material csam\"\n",
    "        ]\n",
    "    },\n",
    "    \"crime against women & children\": {\n",
    "        \"sexual harassment\": [\n",
    "            \"sexual harassment\"\n",
    "        ],\n",
    "        \"computer generated csam/csem\": [\n",
    "            \"computer generated csam/csem\"\n",
    "        ]\n",
    "    },\n",
    "    \"cryptocurrency crime\": {\n",
    "        \"cryptocurrency fraud\": [\n",
    "            \"cryptocurrency fraud\"\n",
    "        ]\n",
    "    },\n",
    "    \"cyber attack/ dependent crimes\": {\n",
    "        \"sql injection\": [\n",
    "            \"sql injection\"\n",
    "        ],\n",
    "        \"ransomware attack\": [\n",
    "            \"ransomware attack\"\n",
    "        ],\n",
    "        \"malware attack\": [\n",
    "            \"malware attack\",\n",
    "            \"malicious code attacks (specifically mentioning virus, worm, trojan, bots, spyware, cryptominers)\"\n",
    "        ],\n",
    "        \"data breach/theft\": [\n",
    "            \"data breach/theft\",\n",
    "            \"data leaks\"\n",
    "        ],\n",
    "        \"hacking/defacement\": [\n",
    "            \"hacking/defacement\",\n",
    "            \"zero-day exploits\",\n",
    "            \"malicious mobile app attacks\"\n",
    "        ],\n",
    "        \"denial of service (dos)/distributed denial of service (ddos) attacks\": [\n",
    "            \"denial of service (dos)/distributed denial of service (ddos) attacks\"\n",
    "        ],\n",
    "        \"tampering with computer source documents\": [\n",
    "            \"tampering with computer source documents\"\n",
    "        ]\n",
    "    },\n",
    "    \"cyber terrorism\": {\n",
    "        \"cyber terrorism\": [\n",
    "            \"cyber terrorism\",\n",
    "            \"cyber espionage\"\n",
    "        ]\n",
    "    },\n",
    "    \"hacking  damage to computercomputer system etc\": {\n",
    "        \"email hacking\": [\n",
    "            \"email hacking\"\n",
    "        ],\n",
    "        \"unauthorised accessdata breach\": [\n",
    "            \"unauthorised accessdata breach\",\n",
    "            \"compromise of critical systems/information\",\n",
    "            \"targeted scanning/probing of critical networks/systems\",\n",
    "            \"attacks on servers (database mail dns) and network devices (routers)\",\n",
    "            \"attacks on critical infrastructure, scada, operational technology systems, and wireless networks\",\n",
    "            \"attacks or suspicious activities affecting cloud computing systems servers software and applications\",\n",
    "            \"attacks or malicious suspicious activities affecting systems related to big data blockchain virtual assets and robotics\",\n",
    "            \"attacks on internet of things (iot) devices and associated systems, networks, and servers\",\n",
    "            \"attacks on systems related to artificial intelligence (ai) and machine learning (ml)\"\n",
    "        ],\n",
    "        \"damage to computer computer systems etc\": [\n",
    "            \"damage to computer computer systems etc\"\n",
    "        ],\n",
    "        \"website defacementhacking\": [\n",
    "            \"web application vulnerabilities\",\n",
    "        ]\n",
    "    },\n",
    "    \"online cyber trafficking\": {\n",
    "        \"online trafficking\": [\n",
    "            \"online trafficking\"\n",
    "        ]\n",
    "    },\n",
    "    \"online financial fraud\": {\n",
    "        \"upi related frauds\": [\n",
    "            \"upi related frauds\",\n",
    "            \"aadhar enabled payment system (aeps) fraud\"\n",
    "        ],\n",
    "        \"business email compromiseemail takeover\": [\n",
    "            \"business email compromiseemail takeover\"\n",
    "        ],\n",
    "        \"debitcredit card fraudsim swap fraud\": [\n",
    "            \"debitcredit card fraudsim swap fraud\"\n",
    "        ],\n",
    "        \"ewallet related fraud\": [\n",
    "            \"ewallet related fraud\"\n",
    "        ],\n",
    "        \"fraud callvishing\": [\n",
    "            \"fraud callvishing\"\n",
    "        ],\n",
    "        \"internet banking related fraud\": [\n",
    "            \"internet banking related fraud\",\n",
    "            \"attacks or incidents affecting digital payment systems\"\n",
    "        ]\n",
    "    },\n",
    "    \"online gambling  betting\": {\n",
    "        \"online gambling  betting\": [\n",
    "            \"online gambling  betting\"\n",
    "        ]\n",
    "    },\n",
    "    \"online and social media related crime\": {\n",
    "        \"intimidating email\": [\n",
    "            \"intimidating email\"\n",
    "        ],\n",
    "        \"provocative speech for unlawful acts\": [\n",
    "            \"provocative speech for unlawful acts\"\n",
    "        ],\n",
    "        \"email phishing\": [\n",
    "            \"email phishing\"\n",
    "        ],\n",
    "        \"online job fraud\": [\n",
    "            \"online job fraud\"\n",
    "        ],\n",
    "        \"profile hacking identity theft\": [\n",
    "            \"profile hacking identity theft\",\n",
    "            \"identity theft, spoofing, and phishing attacks\",\n",
    "            \"unauthorized social media access\"\n",
    "        ],\n",
    "        \"cheating by impersonation\": [\n",
    "            \"cheating by impersonation\",\n",
    "            \"fake mobile apps\"\n",
    "        ],\n",
    "        \"online matrimonial fraud\": [\n",
    "            \"online matrimonial fraud\"\n",
    "        ],\n",
    "        \"cyber bullying  stalking  sexting\": [\n",
    "            \"cyber bullying  stalking  sexting\"\n",
    "        ],\n",
    "        \"fakeimpersonating profile\": [\n",
    "            \"fakeimpersonating profile\"\n",
    "        ]\n",
    "    },\n",
    "    \"rapegang rape rgrsexually abusive content\": {\n",
    "        \"rapegang rape rgrsexually abusive content\": [\n",
    "            \"rapegang rape rgrsexually abusive content\"\n",
    "        ]\n",
    "    },\n",
    "    \"report unlawful content\": {\n",
    "        \"against interest of sovereignty or integrity of india\": [\n",
    "            \"against interest of sovereignty or integrity of india\",\n",
    "            \"disinformation or misinformation campaigns\"\n",
    "        ]\n",
    "    },\n",
    "    \"sexually explicit act\": {\n",
    "        \"sexually explicit act\": [\n",
    "            \"sexually explicit act\"\n",
    "        ]\n",
    "    },\n",
    "    \"sexually obscene material\": {\n",
    "        \"sexually obscene material\": [\n",
    "            \"sale publishing and transmitting obscene material/sexually explicit material\",\n",
    "            \"sexually obscene material\"\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Example usage with your mapping\n",
    "master_mapper = clean_json_mapping(master_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test data...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>category</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>sub_category_names</th>\n",
       "      <th>category_names</th>\n",
       "      <th>retagged_sub_category</th>\n",
       "      <th>retagged_category</th>\n",
       "      <th>content_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>hacking  damage to computercomputer system etc</td>\n",
       "      <td>damage to computer computer systems etc</td>\n",
       "      <td>other</td>\n",
       "      <td>other_cyber_crime</td>\n",
       "      <td>other</td>\n",
       "      <td>any_other_cyber_crime</td>\n",
       "      <td>please read above attached complaint overview ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>online and social media related crime</td>\n",
       "      <td>cheating by impersonation</td>\n",
       "      <td>other</td>\n",
       "      <td>other_cyber_crime</td>\n",
       "      <td>other</td>\n",
       "      <td>any_other_cyber_crime</td>\n",
       "      <td>so agriculture qr neft dr narender sco satyawan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>cyber attack/ dependent crimes</td>\n",
       "      <td>tampering with computer source documents</td>\n",
       "      <td>Email_Phishing</td>\n",
       "      <td>other_cyber_crime</td>\n",
       "      <td>email_phishing</td>\n",
       "      <td>any_other_cyber_crime</td>\n",
       "      <td>this all happened a few days after i accidenta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>cyber attack/ dependent crimes</td>\n",
       "      <td>denial of service (dos)/distributed denial of ...</td>\n",
       "      <td>Email_Phishing</td>\n",
       "      <td>other_cyber_crime</td>\n",
       "      <td>email_phishing</td>\n",
       "      <td>any_other_cyber_crime</td>\n",
       "      <td>this all happened a few days after i accidenta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>cyber attack/ dependent crimes</td>\n",
       "      <td>tampering with computer source documents</td>\n",
       "      <td>Email_Phishing</td>\n",
       "      <td>other_cyber_crime</td>\n",
       "      <td>email_phishing</td>\n",
       "      <td>any_other_cyber_crime</td>\n",
       "      <td>this all happened a few days after i accidenta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19164</th>\n",
       "      <td>18637</td>\n",
       "      <td>online and social media related crime</td>\n",
       "      <td>online job fraud</td>\n",
       "      <td>online_job_fraud</td>\n",
       "      <td>other_cyber_crime</td>\n",
       "      <td>online_job_fraud</td>\n",
       "      <td>online_and_social_media_related_crime</td>\n",
       "      <td>i recieved call on th jan at pm regarding job ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19165</th>\n",
       "      <td>18638</td>\n",
       "      <td>online and social media related crime</td>\n",
       "      <td>cheating by impersonation</td>\n",
       "      <td>online_gambling_betting</td>\n",
       "      <td>financial_fraud_crimes</td>\n",
       "      <td>online_gambling_betting</td>\n",
       "      <td>online_gambling_betting</td>\n",
       "      <td>firstly she say you will get profit by investi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19166</th>\n",
       "      <td>18639</td>\n",
       "      <td>online and social media related crime</td>\n",
       "      <td>cheating by impersonation</td>\n",
       "      <td>fraud_callvishing</td>\n",
       "      <td>financial_fraud_crimes</td>\n",
       "      <td>fraud_callvishing</td>\n",
       "      <td>online_financial_fraud</td>\n",
       "      <td>on date i saw a advertisement of car altoon fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19167</th>\n",
       "      <td>18640</td>\n",
       "      <td>online and social media related crime</td>\n",
       "      <td>cheating by impersonation</td>\n",
       "      <td>cheating_by_impersonation</td>\n",
       "      <td>other_cyber_crime</td>\n",
       "      <td>cheating_by_impersonation</td>\n",
       "      <td>online_and_social_media_related_crime</td>\n",
       "      <td>i surfed facebook and my eye caught one facebo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19168</th>\n",
       "      <td>18641</td>\n",
       "      <td>online and social media related crime</td>\n",
       "      <td>cyber bullying stalking sexting</td>\n",
       "      <td>ewallet_related_fraud</td>\n",
       "      <td>financial_fraud_crimes</td>\n",
       "      <td>ewallet_related_fraud</td>\n",
       "      <td>online_financial_fraud</td>\n",
       "      <td>screen google pay</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19169 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                        category  \\\n",
       "0               0  hacking  damage to computercomputer system etc   \n",
       "1               1           online and social media related crime   \n",
       "2               2                  cyber attack/ dependent crimes   \n",
       "3               3                  cyber attack/ dependent crimes   \n",
       "4               4                  cyber attack/ dependent crimes   \n",
       "...           ...                                             ...   \n",
       "19164       18637           online and social media related crime   \n",
       "19165       18638           online and social media related crime   \n",
       "19166       18639           online and social media related crime   \n",
       "19167       18640           online and social media related crime   \n",
       "19168       18641           online and social media related crime   \n",
       "\n",
       "                                            sub_category  \\\n",
       "0                damage to computer computer systems etc   \n",
       "1                              cheating by impersonation   \n",
       "2               tampering with computer source documents   \n",
       "3      denial of service (dos)/distributed denial of ...   \n",
       "4               tampering with computer source documents   \n",
       "...                                                  ...   \n",
       "19164                                   online job fraud   \n",
       "19165                          cheating by impersonation   \n",
       "19166                          cheating by impersonation   \n",
       "19167                          cheating by impersonation   \n",
       "19168                    cyber bullying stalking sexting   \n",
       "\n",
       "              sub_category_names          category_names  \\\n",
       "0                          other       other_cyber_crime   \n",
       "1                          other       other_cyber_crime   \n",
       "2                 Email_Phishing       other_cyber_crime   \n",
       "3                 Email_Phishing       other_cyber_crime   \n",
       "4                 Email_Phishing       other_cyber_crime   \n",
       "...                          ...                     ...   \n",
       "19164           online_job_fraud       other_cyber_crime   \n",
       "19165    online_gambling_betting  financial_fraud_crimes   \n",
       "19166          fraud_callvishing  financial_fraud_crimes   \n",
       "19167  cheating_by_impersonation       other_cyber_crime   \n",
       "19168      ewallet_related_fraud  financial_fraud_crimes   \n",
       "\n",
       "           retagged_sub_category                      retagged_category  \\\n",
       "0                          other                  any_other_cyber_crime   \n",
       "1                          other                  any_other_cyber_crime   \n",
       "2                 email_phishing                  any_other_cyber_crime   \n",
       "3                 email_phishing                  any_other_cyber_crime   \n",
       "4                 email_phishing                  any_other_cyber_crime   \n",
       "...                          ...                                    ...   \n",
       "19164           online_job_fraud  online_and_social_media_related_crime   \n",
       "19165    online_gambling_betting                online_gambling_betting   \n",
       "19166          fraud_callvishing                 online_financial_fraud   \n",
       "19167  cheating_by_impersonation  online_and_social_media_related_crime   \n",
       "19168      ewallet_related_fraud                 online_financial_fraud   \n",
       "\n",
       "                                       content_processed  \n",
       "0      please read above attached complaint overview ...  \n",
       "1        so agriculture qr neft dr narender sco satyawan  \n",
       "2      this all happened a few days after i accidenta...  \n",
       "3      this all happened a few days after i accidenta...  \n",
       "4      this all happened a few days after i accidenta...  \n",
       "...                                                  ...  \n",
       "19164  i recieved call on th jan at pm regarding job ...  \n",
       "19165  firstly she say you will get profit by investi...  \n",
       "19166  on date i saw a advertisement of car altoon fa...  \n",
       "19167  i surfed facebook and my eye caught one facebo...  \n",
       "19168                                  screen google pay  \n",
       "\n",
       "[19169 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load test data\n",
    "print(\"Loading test data...\")\n",
    "test_df = pd.read_csv('final_test_dataset.csv')\n",
    "\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the text data\n",
    "test_df['content_processed'] = test_df['content_processed'].fillna('')\n",
    "test_df['content_processed'] = test_df['content_processed'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19169 entries, 0 to 19168\n",
      "Data columns (total 8 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   Unnamed: 0             19169 non-null  int64 \n",
      " 1   category               19169 non-null  object\n",
      " 2   sub_category           19168 non-null  object\n",
      " 3   sub_category_names     19169 non-null  object\n",
      " 4   category_names         19169 non-null  object\n",
      " 5   retagged_sub_category  19169 non-null  object\n",
      " 6   retagged_category      19169 non-null  object\n",
      " 7   content_processed      19169 non-null  object\n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading models: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:01<00:00,  6.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing batches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  10%|â–ˆ         | 30/300 [01:46<15:56,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 30/300\n",
      "Current retagged_category Accuracy: 0.7229\n",
      "Current category_names Accuracy: 0.9531\n",
      "Current sub_category_names Accuracy: 0.5125\n",
      "Current retagged_sub_category Accuracy: 0.5208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  20%|â–ˆâ–ˆ        | 60/300 [03:38<15:02,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 60/300\n",
      "Current retagged_category Accuracy: 0.8466\n",
      "Current category_names Accuracy: 0.9617\n",
      "Current sub_category_names Accuracy: 0.5570\n",
      "Current retagged_sub_category Accuracy: 0.5612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  30%|â–ˆâ–ˆâ–ˆ       | 90/300 [05:28<13:11,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 90/300\n",
      "Current retagged_category Accuracy: 0.8799\n",
      "Current category_names Accuracy: 0.9585\n",
      "Current sub_category_names Accuracy: 0.6109\n",
      "Current retagged_sub_category Accuracy: 0.6153\n"
     ]
    }
   ],
   "source": [
    "# Load models and vectorizer\n",
    "encoder, models, label_encoders, selectors = load_models(models_path='models_gdrive/models/')\n",
    "\n",
    "# Run full inference pipeline\n",
    "results_df = run_inference_pipeline(\n",
    "    test_df=test_df,\n",
    "    encoder=encoder,\n",
    "    models=models,\n",
    "    selectors=selectors,\n",
    "    label_encoders=label_encoders,\n",
    "    category_to_sub_category=category_to_sub_category,\n",
    "    master_mapper=master_mapper,\n",
    "    batch_size=64\n",
    ")\n",
    "\n",
    "# Save detailed results\n",
    "save_detailed_results(results_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Analyze specific examples\n",
    "analyze_examples(results_df, test_df)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m124",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m124"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
