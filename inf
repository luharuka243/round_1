import torch
import torch.nn as nn
import torchtext
from encoder_only_transformer_ag_news_classification__1_ import Transformer, ModelConfig, make_model, tokenizer, word_to_id, UNK, DEVICE, PAD, max_seq_len

# --- 1. Define Paths to Your Checkpoint Files ---
model_1_checkpoint_path = 'model_1_checkpoint.pth'  # Replace with your actual path
c1_model_checkpoint_path = 'c1_model_checkpoint.pth' # Replace with your actual path
c2_model_checkpoint_path = 'c2_model_checkpoint.pth' # Replace with your actual path
c3_model_checkpoint_path = 'c3_model_checkpoint.pth' # Replace with your actual path
c4_model_checkpoint_path = 'c4_model_checkpoint.pth' # Replace with your actual path

# --- 2. Define Model Configurations (adjust as needed for each model if different) ---
# Assuming all models have the same base config, but you might need to adjust
# vocab_size and num_classes for category-specific models if they are different.
base_config = ModelConfig(encoder_vocab_size = 15000, # vocab_size from your training script
                     d_embed = 32,
                     d_ff = 4*32,
                     h = 1,
                     N_encoder = 1,
                     max_seq_len = max_seq_len,
                     dropout = 0.1
                     )

# --- 3. Load Model Checkpoints ---
def load_checkpoint(model_path, config, num_classes):
    model = make_model(config) # Create model structure first
    checkpoint = torch.load(model_path, map_location=DEVICE) # Load checkpoint on appropriate device
    model.load_state_dict(checkpoint['model_state_dict']) # Load the model's state
    model.to(DEVICE) # Ensure model is on the correct device after loading
    model.eval() # Set to evaluation mode
    return model

# Model 1 (Predicts initial 4 categories)
model_1 = load_checkpoint(model_1_checkpoint_path, base_config, num_classes=4) # Assuming model_1 predicts 4 categories

# Category-Specific Models (Adjust num_classes if needed for sub-categories)
c1_model = load_checkpoint(c1_model_checkpoint_path, base_config, num_classes= /* number of classes for c1_model, e.g., 5 */ ) # Replace with actual number of classes
c2_model = load_checkpoint(c2_model_checkpoint_path, base_config, num_classes= /* number of classes for c2_model */ ) # Replace with actual number of classes
c3_model = load_checkpoint(c3_model_checkpoint_path, base_config, num_classes= /* number of classes for c3_model */ ) # Replace with actual number of classes
c4_model = load_checkpoint(c4_model_checkpoint_path, base_config, num_classes= /* number of classes for c4_model */ ) # Replace with actual number of classes

# --- 4. Category Label Mapping (for Model 1 output) ---
# Adjust these labels to match what your model_1 was trained to predict.
model_1_category_labels = {
    0: "Category_C1", # Index 0 corresponds to Category C1
    1: "Category_C2", # Index 1 corresponds to Category C2
    2: "Category_C3", # Index 2 corresponds to Category C3
    3: "Category_C4"  # Index 3 corresponds to Category C4
}

# --- 5. Function for Hierarchical Classification ---
def hierarchical_classify_text(text):
    # --- Preprocess Input Text ---
    x_text = tokenizer(text.lower())[0:max_seq_len]
    x_int = torch.tensor([[word_to_id.get(word, UNK) for word in x_text]]).to(DEVICE)

    # --- Model 1 Prediction ---
    with torch.no_grad():
        pad_mask = (x_int == PAD).view(x_int.size(0), 1, 1, x_int.size(-1))
        model_1_pred = model_1(x_int, pad_mask)
        model_1_predicted_category_index = model_1_pred.argmax(1).item()
        model_1_predicted_category_label = model_1_category_labels[model_1_predicted_category_index]

    print(f"Model 1 Prediction: {model_1_predicted_category_label}")

    # --- Conditional Calling of Category-Specific Models ---
    category_specific_prediction = "No further prediction" # Default if no category-specific model is called or has issues
    if model_1_predicted_category_label == "Category_C1":
        with torch.no_grad():
            pad_mask = (x_int == PAD).view(x_int.size(0), 1, 1, x_int.size(-1))
            c1_pred = c1_model(x_int, pad_mask)
            c1_predicted_sub_category_index = c1_pred.argmax(1).item()
            category_specific_prediction = f"C1 Model Prediction (Sub-Category Index): {c1_predicted_sub_category_index}" # You'd likely have labels for sub-categories too
    elif model_1_predicted_category_label == "Category_C2":
        with torch.no_grad():
            pad_mask = (x_int == PAD).view(x_int.size(0), 1, 1, x_int.size(-1))
            c2_pred = c2_model(x_int, pad_mask)
            c2_predicted_sub_category_index = c2_pred.argmax(1).item()
            category_specific_prediction = f"C2 Model Prediction (Sub-Category Index): {c2_predicted_sub_category_index}"
    elif model_1_predicted_category_label == "Category_C3":
        with torch.no_grad():
            pad_mask = (x_int == PAD).view(x_int.size(0), 1, 1, x_int.size(-1))
            c3_pred = c3_model(x_int, pad_mask)
            c3_predicted_sub_category_index = c3_pred.argmax(1).item()
            category_specific_prediction = f"C3 Model Prediction (Sub-Category Index): {c3_predicted_sub_category_index}"
    elif model_1_predicted_category_label == "Category_C4":
        with torch.no_grad():
            pad_mask = (x_int == PAD).view(x_int.size(0), 1, 1, x_int.size(-1))
            c4_pred = c4_model(x_int, pad_mask)
            c4_predicted_sub_category_index = c4_pred.argmax(1).item()
            category_specific_prediction = f"C4 Model Prediction (Sub-Category Index): {c4_predicted_sub_category_index}"

    print(category_specific_prediction)


# --- 6. Example Usage ---
input_text = """This article discusses the latest advancements in artificial intelligence and machine learning,
with a focus on deep learning techniques and their applications in various industries."""
hierarchical_classify_text(input_text)

input_text_2 = "Breaking news! The stock market experienced a significant surge today, with tech companies leading the gains."
hierarchical_classify_text(input_text_2)

input_text_3 = "In a thrilling match last night, the home team secured a victory in the final seconds, sparking celebrations among fans."
hierarchical_classify_text(input_text_3)
